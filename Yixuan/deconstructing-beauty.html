<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Document</title>
    <link href="../css/projectPage.css" rel="stylesheet" />
    <link href="../css/infoWrapper.css" rel="stylesheet" />
    <link href="../css/stardom.css" rel="stylesheet" />
    <link href="./yixuan.css" rel="stylesheet" />
    <link
      href="https://api.fontshare.com/v2/css?f[]=satoshi@1,900,700,500,301,701,300,501,401,901,400,2&display=swap"
      rel="stylesheet"
    />
  </head>
  <body>
    <div class="marquee">
      <span>
        Deconstructing Beauty Deconstructing Beauty Deconstructing Beauty
        Deconstructing Beauty Deconstructing Beauty
      </span>
    </div>
    <div class="container">
      <div class="left--1">
        <div class="infoWrapper">
          <div class="info-key info-key--1">DESIGNER</div>
          <div class="info info--1">
            <span>Yixuan Ding</span>
            <!-- <span style="font-size: 14px">姜 禹汉</span> -->
          </div>
          <div class="info-key info-key--2">KEYWORD</div>
          <div class="info info--2">
            #Beauty<br />
            #Bias<br />
            #Artificial Intelligence<br />
            #Fashion
          </div>
          <div class="info-key info-key--3">ADVISOR</div>
          <div class="info info--3">Bolor Amgalan</div>
        </div>
      </div>
      <div class="mid--1">
        <p>
          This project focus on how human bias about body image aesthetics
          changes over time with a critical analysis of fashion media and the
          capabilities of some existing generative artificial intelligence (AI)
          tools. It aims to further shed light on the inherent bias in
          artificial intelligence systems that manifest in the form of
          artificially generated body conformity with potential sociocultural
          implications. To demonstrates how to work with existing, pre-trained
          artificial intelligence art generator tools to produce results that
          reflect diverse beauty standards. Examine how the concept of
          posthumanism can be introduced to the designer’s workflow in the form
          of text prompts when collaborating with AI generative tools to create
          inclusive fashion visuals. 
        </p>
        <img src="../assets/Yixuan/high heel.png" id="outlier" />
      </div>
      <div class="right--1"></div>
      <div class="left--2 subtitle">
        <span>Why I chose this topic</span>
      </div>
      <div class="mid--2" id="subtitle1">
        <p>
          Throughout history, the aesthetic of body image and the definition of
          the “ideal body” have always changed depending on different eras and
          social backgrounds. Beauty standards from ancient Egypt to the present
          day have been shaped by cultures from both the East and the West.
          People consistently describe the “ideal” body image as iconic based on
          different cultural norms, perceptions, opinions, standards, and
          preferences.
        </p>
        <br />
        <p>
          Nowadays, the world revolves around data, numbers, information, and
          forms. Using techniques to make data visible is what data
          visualization does. The information can contain various types of
          content. It is not limited to numbers. Image dataset means images can
          also be a dataset to collect, categorize and analyze. Generative
          Adversarial Networks (GANs) are a type of generative modeling that
          utilizes deep learning techniques, including convolutional neural
          networks (CNNs), as well as an adversarial training process to
          generate new data that resembles the original training data.
        </p>
        <br />
        <img src="../assets/Yixuan/1.png" alt="image" />
      </div>
      <div class="right--2"></div>
      <div class="left--3 subtitle">
        <!-- <a href="#subtitle2">Why use cartoon character card</a> -->
        <span>Methodology</span>
      </div>
      <div class="mid--3" id="subtitle2">
        <img src="../assets/Yixuan/2.jpg" alt="image" id="float-right" />
        <p>
          Based on my hypothesis about artificial intelligence beauty bias, the
          design approach of my experiment is to test this beauty bias and find
          method to improve this experience, or in other word to say, find a way
          to find the fairness, diversity and inclusive. In contrast to my
          original plan of manually analyzing body images for beauty, I
          incorporate existing machine-learning models to assist with the
          critique process. This approach still aims at identifying and
          addressing beauty bias. However, the questions have become more
          focused on specific aspects such as skin tone, body shape, or clothing
          texture.
        </p>
      </div>
      <div class="right--3"></div>
      <div class="left--4 subtitle">
        <span>Prompt</span>
      </div>
      <div class="mid--4" id="subtitle3">
        <p>
          The aim of this data visualization is to provide a guideline about the
          prompt word used on Midjourny.
        </p>
        <br />
        <p>
          The primary prompt was “Fashion model beauty” and “Posthumanism and
          Futuristic” as an art style. Keep inputting the command to add and
          remove synonyms and related key terms to see what could emerge after
          changing. Also, set the background as flowers to distinguish
          differences and the content styles.
        </p>
        <br />
        <img src="../assets/Yixuan/3.jpg" alt="image" />
      </div>

      <div class="right--4"></div>
      <div class="left--5 subtitle">
        <span>Data Visualization Result</span>
      </div>
      <div class="mid--5" id="subtitle4">
        <img src="../assets/Yixuan/dataviz1.jpg" alt="image" />
        <img src="../assets/Yixuan/dataviz2.jpg" alt="image" />
        <p>
          I tested the listed keywords from Circular dendrogram, as these are
          cascade related. However, only some of the keywords produced the
          desired results. The images were reorganized and rearranged so that
          viewers can observe and compare the differences between these
          artworks. Images and prompts are produced after filter layers. In the
          picture, (Figure. 34)  shown here, see some initial input words and
          phrases such as “fashion magazine mode” and “Posthumanism fashion
          model beauty,” “Posthumanism Beauty.” By adding related words like
          diverse, and aging, we get other aspects of beauty. So, discover the
          images’ color, skin tone, and body shape as the primary focus. 
        </p>
        <br />
        <img src="../assets/Yixuan/4.png" alt="image" />
        <br />
        <p>
          The Midjourney itself exerts stereotypes, and it somehow displays
          specific “disrespectful” photos without the ability to identify them.
          But all of this comes from learning from its original initial dataset
          of thousands of photos. In other words, AI bias is also human bias.
          The process and result of AI learning from an extensive database of
          images to produce new art paintings is an innovative form of art
          creation. The artists can filter image details through input and
          output. Therefore, humans remain the most crucial factor and the main
          source of decision-making. With prompt keywords to input, we need to
          be specific on what, when, and how. The keywords should be as specific
          as possible to avoid Image bias and stereotypes. Because the AI do not
          have imagination on create image.
        </p>
        <br />
        <img src="../assets/Yixuan/5.jpg" alt="image" />
        <!-- <br /> -->
        <br />
        <img src="../assets/Yixuan/cover_yixuan.jpg" alt="image" />
      </div>

      <div class="right--5"></div>
    </div>
    <footer></footer>
    <script>
      const infokey1 = document.querySelector('.info-key--1')
      const infokey2 = document.querySelector('.info-key--2')
      const infokey3 = document.querySelector('.info-key--3')

      const splitWord = function (el) {
        return (el.innerHTML = el.innerText
          .split('')
          .map((e) => (!e.trim() ? '<div>&nbsp</div>' : `<div>${e}</div>`))
          .join(''))
      }
      splitWord(infokey1)
      splitWord(infokey2)
      splitWord(infokey3)

      const subTitle1 = document.querySelector('.left--2 ')
      const subTitle2 = document.querySelector('.left--3 ')
      const subTitle3 = document.querySelector('.left--4 ')
      const subTitle4 = document.querySelector('.left--5 ')
      const para1 = document.querySelector('#subtitle1')
      const para2 = document.querySelector('#subtitle2')
      const para3 = document.querySelector('#subtitle3')
      const para4 = document.querySelector('#subtitle4')

      const navInto = function (triggerEl, changedEl) {
        triggerEl.addEventListener('click', () => {
          changedEl.scrollIntoView({
            behavior: 'smooth',
            block: 'end',
            inline: 'center',
          })
        })
      }

      const navTo = function (triggerEl, changedEl) {
        triggerEl.addEventListener('click', () => {
          document.documentElement.scrollBy({
            top:
              changedEl.getBoundingClientRect().top -
              triggerEl.getBoundingClientRect().top,
            left: 0,
            behavior: 'smooth',
          })
        })
      }

      navTo(subTitle1, para1, 100)
      navTo(subTitle2, para2, 136)
      navTo(subTitle3, para3)
      navTo(subTitle4, para4)

      window.addEventListener('scroll', (e) => {
        console.log('---')
        console.log(window.scrollY)
        console.log(subTitle2.getBoundingClientRect().top)
        console.log(para2.getBoundingClientRect().top)
        console.log(getOffset(subTitle2).top)
        console.log(getOffset(para2).top)
        console.log('---')
      })

      function getOffset(el) {
        const rect = el.getBoundingClientRect()
        return {
          left: rect.left + window.scrollX,
          top: rect.top + window.scrollY,
        }
      }
    </script>
  </body>
</html>
